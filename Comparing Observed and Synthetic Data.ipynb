{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Comparing Observed and Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from obspy.clients.fdsn.client import Client\n",
    "from obspy.clients.fdsn.mass_downloader import GlobalDomain\n",
    "from obspy.clients.fdsn.mass_downloader import MassDownloader\n",
    "from obspy.clients.fdsn.mass_downloader import Restrictions\n",
    "from obspy import UTCDateTime\n",
    "from obspy.geodetics import calc_vincenty_inverse\n",
    "from obspy.geodetics import locations2degrees\n",
    "\n",
    "from obspy.signal.invsim import cosine_sac_taper\n",
    "from obspy.signal.util import _npts2nfft\n",
    "import obspy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "def reread_data():\n",
    "    global synt1d, synt3d, obsd\n",
    "    synt1d = obspy.read(synt1d_filename)[0]\n",
    "    synt3d = obspy.read(synt3d_filename)[0]\n",
    "    obsd = obspy.read(obsd_filename)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data from ShakeMovie\n",
    "\n",
    "> [Global ShakeMovie](http://global.shakemovie.princeton.edu/home.jsp) is Princeton University's Near Real Time Global Seismicity Portal. It has been designed to present seismologists with near real time 1D and 3D synthetic seismograms for recent earthquakes. These synthetics are the results of simulations carried out on a large computer cluster. 1D synthetic seismograms are calculated based upon normal mode summation. Movies and 3D synthetic seismograms are calculated based upon the software package SPECFEM3D_GLOBE. \n",
    "\n",
    "\n",
    "You can download movies and data for earthquakes from this website. For the purpose of this exercise we have selected September 10, 2018 Earthquake (Mw: 7.0) near KERMADEC ISLANDS ([link](http://global.shakemovie.princeton.edu/event.jsp?evid=C201809100418A)).\n",
    "\n",
    "We have downloaded 1D and 3D synthetic seismograms for this earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read synthetic data\n",
    "synt1d_filename = \"./C201809100418A.1D.sac/IU.ANTO.LXZ.modes.sac\"\n",
    "synt3d_filename = \"./C201809100418A.3D.sac/IU.ANTO.MXZ.sem.sac\"\n",
    "\n",
    "synt1d = obspy.read(synt1d_filename)[0]\n",
    "synt3d = obspy.read(synt3d_filename)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Event Information\n",
    "\n",
    "You can download the HARVARD CMT SOLUTION from ShakeMovie website. Obspy also provides tools to download event information from [IRIS](https://www.iris.edu/hq/) database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eqname = \"C201809100418A\"\n",
    "quakeml_filename = \"quakeml/{}.xml\".format(eqname)\n",
    "\n",
    "def download_events(force_download=False):\n",
    "    if force_download or not os.path.exists(quakeml_filename):\n",
    "        cl = Client()\n",
    "        t1 = UTCDateTime(\"2018-09-10T00:00:00\")\n",
    "        t2 = UTCDateTime(\"2018-09-11T00:00:00\")\n",
    "\n",
    "        cat = cl.get_events(starttime=t1, endtime=t2, minmagnitude=6.9,\n",
    "                            maxmagnitude=7.1)\n",
    "\n",
    "        os.makedirs(\"quakeml\", exist_ok=True)\n",
    "        cat.write(quakeml_filename, \"QUAKEML\")\n",
    "    \n",
    "download_events()\n",
    "cat = obspy.read_events(quakeml_filename)\n",
    "cat.plot(projection=\"ortho\", show=False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Seismic Data\n",
    "\n",
    "We can also download seismic recordings and instrumentation information using obspy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = Client(\"IRIS\")\n",
    "inv = cl.get_stations(\n",
    "    starttime=UTCDateTime(\"2018-09-10T00:00:00\"), \n",
    "    endtime=UTCDateTime(\"2018-09-10T01:00:00\"),\n",
    "    matchtimeseries=True,\n",
    "    channel=\"BH*\",\n",
    "    includerestricted=False,\n",
    "    level=\"channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv.plot(label=False, size=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(eqname, t0, lat, lon, min_length=180):\n",
    "    domain = GlobalDomain()\n",
    "\n",
    "    restrictions = Restrictions(\n",
    "        # Get data for a whole year.\n",
    "        starttime=t0,\n",
    "        endtime=t0+60*min_length,\n",
    "        # Chunk it to have one file per day.\n",
    "        chunklength_in_sec=86400,\n",
    "        # Considering the enormous amount of data associated with continuous\n",
    "        # requests, you might want to limit the data based on SEED identifiers.\n",
    "        # If the location code is specified, the location priority list is not\n",
    "        # used; the same is true for the channel argument and priority list.\n",
    "        network=\"IU\", station=\"AN*\", location=\"*\", channel=\"BH*\",\n",
    "        # The typical use case for such a data set are noise correlations where\n",
    "        # gaps are dealt with at a later stage.\n",
    "        reject_channels_with_gaps=True,\n",
    "        # Same is true with the minimum length. All data might be useful.\n",
    "        minimum_length=0.0,\n",
    "        # Guard against the same station having different names.\n",
    "        minimum_interstation_distance_in_m=100.0)\n",
    "\n",
    "    waveform_dir = \"data/{}/waveforms\".format(eqname)\n",
    "    stationxml_dir = \"data/{}/stations\".format(eqname)\n",
    "    os.makedirs(waveform_dir, exist_ok=True)\n",
    "    os.makedirs(stationxml_dir, exist_ok=True)\n",
    "\n",
    "    mdl = MassDownloader(providers=[\"IRIS\"])\n",
    "    mdl.download(domain, restrictions,\n",
    "                 mseed_storage=waveform_dir,\n",
    "                 stationxml_storage=stationxml_dir)\n",
    "\n",
    "event = cat[0]\n",
    "origin = event.preferred_origin()\n",
    "download_data(eqname, origin.time-30, origin.latitude, origin.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsd_filename = \"./data/C201809100418A/waveforms/IU.ANTO.00.BHZ__20180910T041832Z__20180910T071832Z.mseed\"\n",
    "obsd = obspy.read(obsd_filename)[0]\n",
    "obsd.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6), subplot_kw=dict(projection=ccrs.Robinson(central_longitude=origin.longitude)))\n",
    "ax.set_global()\n",
    "ax.coastlines()\n",
    "ax.add_feature(cfeature.LAND)\n",
    "inv = obspy.read_inventory(\"./data/C201809100418A/stations/IU.ANTO.xml\")\n",
    "sta_coord = inv.get_coordinates(obsd.id)\n",
    "\n",
    "ax.scatter(origin.longitude, origin.latitude, 200, marker=\"*\", color=\"red\", transform=ccrs.PlateCarree(), zorder=100)\n",
    "ax.scatter(sta_coord[\"longitude\"], sta_coord[\"latitude\"], 200, marker=\"v\", color=\"blue\", transform=ccrs.PlateCarree(), zorder=100)\n",
    "ax.plot([origin.longitude, sta_coord[\"longitude\"]], [origin.latitude, sta_coord[\"latitude\"]], \"k\", transform=ccrs.Geodetic());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the data\n",
    "\n",
    "If we try to compare the observed and synthetic data without any processing, we can see that they are not similar enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, sharex=True, figsize=(12, 6))\n",
    "axes[0].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[0].legend(loc=2)\n",
    "axes[0].set_ylabel(\"COUNTS\")\n",
    "\n",
    "axes[1].plot(synt1d.times(), synt1d.data, \"k\", label=\"synt (1D)\")\n",
    "axes[1].legend(loc=2)\n",
    "axes[1].set_ylabel(\"Displacement (m)\")\n",
    "\n",
    "axes[2].plot(synt3d.times(), synt3d.data, \"k\", label=\"synt (3D)\")\n",
    "axes[2].set_ylabel(\"Displacement (m)\")\n",
    "axes[2].set_xlabel(\"Time (s)\")\n",
    "axes[2].set_xlim(0, 6000)\n",
    "\n",
    "axes[2].legend(loc=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutting and Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "traces = [obsd, synt1d, synt3d]\n",
    "starts = []\n",
    "ends = []\n",
    "for trace in traces:\n",
    "    starts.append(trace.stats.starttime)\n",
    "    ends.append(trace.stats.endtime)\n",
    "    print(f\"{trace.id} sampling rate: {trace.stats.sampling_rate:5.2f} start: {starts[-1]} end: {ends[-1]}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "obsd.interpolate?\n",
    "    \n",
    "# for trace in traces:\n",
    "#     print(f\"{trace.id} sampling rate: {trace.stats.sampling_rate:5.2f} start: {starts[-1]} end: {ends[-1]}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, sharex=True, figsize=(12, 6))\n",
    "axes[0].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[0].legend(loc=2)\n",
    "axes[0].set_ylabel(\"COUNTS\")\n",
    "\n",
    "axes[1].plot(synt1d.times(), synt1d.data, \"k\", label=\"synt (1D)\")\n",
    "axes[1].legend(loc=2)\n",
    "axes[1].set_ylabel(\"Displacement (m)\")\n",
    "\n",
    "axes[2].plot(synt3d.times(), synt3d.data, \"k\", label=\"synt (3D)\")\n",
    "axes[2].set_ylabel(\"Displacement (m)\")\n",
    "axes[2].set_xlabel(\"Time (s)\")\n",
    "axes[2].set_xlim(0, 6000)\n",
    "\n",
    "axes[2].legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Removing Instrument Response\n",
    "\n",
    "Observed data:\n",
    "\n",
    "$$\n",
    "obsd = \\text{source} * \\text{model} * \\text{instrument}\n",
    "$$\n",
    "\n",
    "Synthetic data:\n",
    "\n",
    "$$\n",
    "synt = \\text{source} * \\text{model}\n",
    "$$\n",
    "\n",
    "In order to compare the data, we need to deconvolve the instrument response from observed data and filter both data to a comparable frequency range.\n",
    "\n",
    "We downloaded *StationXML* files with the seismic data. These files contain information about stations like location and response function. We can use this information to remove the instrument response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the instrument data\n",
    "inv = obspy.read_inventory(\"./data/C201809100418A/stations/IU.ANTO.xml\")\n",
    "obsd.attach_response(inv)\n",
    "# Remove mean and the linear trend\n",
    "obsd.detrend(\"demean\")\n",
    "obsd.detrend(\"linear\")\n",
    "# Taper\n",
    "obsd.taper(0.05)\n",
    "\n",
    "min_period = 100\n",
    "max_period = 250\n",
    "\n",
    "# Define a pre-filter and remove the response function\n",
    "pre_filt = [0.8*(1.0/max_period), (1.0/max_period), (1.0/min_period), 1.2*(1.0/min_period)]\n",
    "obsd.remove_response?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "Now if we plot the traces again we can see that, they are still not comparable. We need to apply the same filter to the synthetic data we used for observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, sharex=True, figsize=(12, 6))\n",
    "axes[0].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[0].legend(loc=2)\n",
    "axes[0].set_ylabel(\"Displacement (m)\")\n",
    "\n",
    "axes[1].plot(synt1d.times(), synt1d.data, \"k\", label=\"synt (1D)\")\n",
    "axes[1].legend(loc=2)\n",
    "axes[1].set_ylabel(\"Displacement (m)\")\n",
    "\n",
    "axes[2].plot(synt3d.times(), synt3d.data, \"k\", label=\"synt (3D)\")\n",
    "axes[2].set_ylabel(\"Displacement (m)\")\n",
    "axes[2].set_xlabel(\"Time (s)\")\n",
    "axes[2].set_xlim(0, 6000)\n",
    "\n",
    "axes[2].legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sac_taper(tr):\n",
    "    tr.detrend(\"demean\")\n",
    "    tr.detrend(\"linear\")\n",
    "    tr.taper(0.05)\n",
    "    nfft = _npts2nfft(len(tr.data))\n",
    "    data = np.fft.rfft(tr.data, nfft)\n",
    "    fy = 1.0 / (tr.stats.delta * 2.0)\n",
    "    freqs = np.linspace(0, fy, nfft//2+1)\n",
    "    data *= cosine_sac_taper(freqs, flimit=pre_filt)\n",
    "    tr.data = np.fft.irfft(data)[0:len(tr.data)]\n",
    "    \n",
    "# use sac taper on synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Comparisons\n",
    "Finally, we can compare the observed and synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, sharex=True, figsize=(12, 6))\n",
    "axes[0].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[0].legend(loc=2)\n",
    "\n",
    "axes[1].plot(synt1d.times(), synt1d.data, \"k\", label=\"synt (1D)\")\n",
    "axes[1].legend(loc=2)\n",
    "\n",
    "axes[2].plot(synt3d.times(), synt3d.data, \"k\", label=\"synt (3D)\")\n",
    "axes[2].set_xlim(0, 6000)\n",
    "axes[2].legend(loc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin, tmax = 1000, 6000\n",
    "xmin, xmax = np.abs(obsd.times()-tmin).argmin(), np.abs(obsd.times()-tmax).argmin()\n",
    "ymin, ymax = np.min(obsd.data[xmin:xmax])*1.2, np.max(obsd.data[xmin:xmax])*1.2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, sharex=True, figsize=(12, 6))\n",
    "axes[0].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[0].plot(synt1d.times(), synt1d.data, \"r\", label=\"synt (1D)\")\n",
    "axes[0].set_ylim(ymin, ymax)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(obsd.times(), obsd.data, \"k\", label=\"obsd\")\n",
    "axes[1].plot(synt3d.times(), synt3d.data, \"r\", label=\"synt (3D)\")\n",
    "axes[1].set_xlim(tmin, tmax)\n",
    "axes[1].set_ylim(ymin, ymax)\n",
    "axes[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the time shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut the data between 4300, 5000\n",
    "tmin, tmax = 4300, 5000\n",
    "obsd_sw = obsd.copy()\n",
    "obsd_sw.trim?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xcorr_shift(d, s):\n",
    "    \"Returns the time shift where the crosscorrelation is maximum\"\n",
    "    cc = np.correlate(d.data, s.data, mode=\"full\")\n",
    "    time_shift = cc.argmax() - len(d.data) + 1\n",
    "    return time_shift*d.stats.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the time shifts between the data"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "obspy3",
   "language": "python",
   "name": "obspy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
